{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tqdm in /home/peshmerge/.local/lib/python3.8/site-packages (4.62.3)\n"
     ]
    }
   ],
   "source": [
    "# !pip install pandas\n",
    "# !pip install pyarrow\n",
    "# !pip install geopandas\n",
    "# !pip install matplotlib\n",
    "# !pip install seaborn\n",
    "# !pip install pyproj\n",
    "# !pip install geopy\n",
    "# !pip install \"geopy[aiohttp]\"\n",
    "# !pip install tqdm\n",
    "import logging\n",
    "import os\n",
    "from random import randint\n",
    "from time import sleep\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from geopy.adapters import AioHTTPAdapter\n",
    "from geopy.exc import GeocoderServiceError, GeocoderTimedOut\n",
    "from geopy.geocoders import Nominatim\n",
    "from shapely.geometry import Polygon\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geopy_client_geo_reverse(geolocator, coordinate):\n",
    "    location = geolocator.reverse(coordinate, timeout = 3, language=\"en\")\n",
    "    country = location.raw.get('address').get('country')\n",
    "    print(\"Coordinates \" + coordinate , \" Country: \" + country , \" file name: \" + file_name)\n",
    "    return country\n",
    "    \n",
    "def convert_polygon_to_country(poly_items, file_name):\n",
    "    return_list= [] \n",
    "    index = 0\n",
    "    print(str(len(poly_items)) + \" rows have been given initially to the script \")\n",
    "    for poly_item in tqdm(poly_items):\n",
    "        longitude,latitude = poly_item.bounds[:2]\n",
    "        my_user_agent = 'UTwente_Managing_Big_Data_project_{}'.format(randint(10000,99999))\n",
    "        geolocator = Nominatim(user_agent = my_user_agent)\n",
    "        coordinate = str(latitude) +\",\"+ str(longitude)\n",
    "        try:\n",
    "            country = geopy_client_geo_reverse(geolocator, coordinate)\n",
    "            return_list.append(country)\n",
    "            index = index +1\n",
    "        except GeocoderTimedOut:\n",
    "            logging.info('TIMED OUT: GeocoderTimedOut: Retrying...')\n",
    "            sleep(randint(1*100,5*100)/100)\n",
    "            country = geopy_client_geo_reverse(geolocator, coordinate)\n",
    "            return_list.append(country)\n",
    "        except GeocoderServiceError as e:\n",
    "            logging.info('CONNECTION REFUSED: GeocoderServiceError encountered.')\n",
    "            logging.error(e)\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            logging.info('ERROR: Terminating due to exception {}'.format(e))\n",
    "            return None    \n",
    "    print(str(index) + \" have been processed \")\n",
    "    print(str(len(poly_items)) + \" have been given initially to the script \")\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for subdir, dirs, files in os.walk('dataset'):\n",
    "    for file in files:\n",
    "        if file.endswith('shp'):\n",
    "            file_name = os.path.join(subdir,file)\n",
    "            print(\"Reading now from \" + file_name )\n",
    "            shape_file = gpd.read_file(file_name)\n",
    "           \n",
    "            new_file_name = 'countries_' + file.split('.')[0] +'.parquet'\n",
    "            new_file_path = os.path.join(subdir,new_file_name)\n",
    "            \n",
    "            print(\"Create new parquet files ..............\")\n",
    "            \n",
    "            parquet_file = pd.DataFrame(columns=['quadkey','avg_d_kbps','avg_u_kbps','avg_lat_ms','tests','devices', 'tile'])\n",
    "            parquet_file.quadkey = shape_file.quadkey\n",
    "            parquet_file.avg_d_kbps = shape_file.avg_d_kbps\n",
    "            parquet_file.avg_u_kbps = shape_file.avg_u_kbps\n",
    "            parquet_file.avg_lat_ms = shape_file.avg_lat_ms\n",
    "            parquet_file.tests = shape_file.tests\n",
    "            parquet_file.devices = shape_file.devices\n",
    "\n",
    "            print(\"Converting polygons to countries ..............\")\n",
    "            parquet_file.tile = convert_polygon_to_country(shape_file.geometry,file_name)\n",
    "            # parquet_file = pd.read_parquet('dataset/2019-q1/countries_gps_fixed_tiles.parquet', engine='pyarrow')\n",
    "            print(\"Writing now to \" + new_file_path)\n",
    "            parquet_file.to_parquet(new_file_path)\n",
    "            print(\"Finished ...................................................\")\n",
    "            \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subdir, dirs, files in os.walk('dataset'):\n",
    "    for file in files:\n",
    "        if file.startswith('countries'):\n",
    "            file_name = os.path.join(subdir,file)\n",
    "            parquet_file = pd.read_parquet(file_name, engine='pyarrow')\n",
    "            display(parquet_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_file = gpd.read_file('dataset/2019-q1/gps_fixed_tiles.shp')\n",
    "print(len(shape_file.index))\n",
    "# parquet_file = pd.read_parquet('dataset/2019-q1/2019-01-01_performance_fixed_tiles.parquet', engine='pyarrow')\n",
    "# display(shape_file)\n",
    "# display(parquet_file)\n",
    "# parquet_file = pd.DataFrame(columns=['quadkey','country'])\n",
    "# parquet_file.quadkey = shape_file.quadkey\n",
    "# parquet_file.country = convert_polygon_to_country(shape_file.geometry)\n",
    "# parquet_file.to_parquet('dataset/2019-q1/countries_gps_fixed_tiles.parquet')\n",
    "# parquet_file = pd.read_parquet('dataset/2019-q1/countries_gps_fixed_tiles.parquet', engine='pyarrow')\n",
    "# display(parquet_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(shape_file.iloc[4788])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_row_count = 0\n",
    "for subdir, dirs, files in os.walk('dataset'):\n",
    "    for file in files:\n",
    "        if file.endswith('parquet'):\n",
    "            file_df = pd.read_parquet(os.path.join(subdir,file))\n",
    "            total_row_count += len(file_df.index)\n",
    "            print(file + \"containts \", str(len(file_df.index)) + \" rows\")\n",
    "\n",
    "print(\"total count \", str(total_row_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "q1_2019 = 'dataset/2019-q1/2019-01-01_performance_fixed_tiles.parquet' \n",
    "q1_df = pd.read_parquet(q1_2019, engine='pyarrow', columns=['quadkey', 'tile'])\n",
    "pd.set_option('display.max_colwidth', 3000)\n",
    "display(q1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "q1_shape_file = gpd.read_file('dataset/2019-q1/gps_fixed_tiles.shp', driver='shapely')\n",
    "q1_shape_file.head()\n",
    "display(q1_shape_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_parquet_file1 = q1_shape_file.iloc[:2]\n",
    "q1_parquet_file =  q1_parquet_file1[['quadkey','geometry']].copy()\n",
    "q1_parquet_file1.head()\n",
    "q1_parquet_file.to_file('dataset/2019-q1/2019-01-01_performance_fixed_tiles_countries.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_file = gpd.read_file('dataset/2019-q1/2019-01-01_performance_fixed_tiles_countries.shp')\n",
    "parquet_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_polygons_with_countries_in_given_parquet_file(file_path):\n",
    "    parquet_file = pd.read_parquet(file_path, engine='pyarrow')\n",
    "    parquet_file_len = len(parquet_file.index)\n",
    "    print(\"length \" + str(parquet_file_len))\n",
    "    index = 0\n",
    "    while index < parquet_file_len:\n",
    "        parquet_file = pd.read_parquet(file_path, engine='pyarrow')\n",
    "        temp_index = index\n",
    "        for inner_index in range(index, temp_index + 100):\n",
    "            parquet_file.loc[inner_index,'geometry'] = convert_polygon_to_country(parquet_file.loc[inner_index,'geometry'])\n",
    "        parquet_file.to_parquet('dataset/2019-q1/2019-01-01_performance_fixed_tiles_countries.parquet', index=False)\n",
    "        index =  inner_index   \n",
    "    # list_of_polygons = q1_csv_file['geometry']\n",
    "\n",
    "replace_polygons_with_countries_in_given_parquet_file('dataset/2019-q1/2019-01-01_performance_fixed_tiles_countries.parquet')    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b5d5ac7a7bfad39d13684607cb7a8589ceef353fd9fd58484c2060c3ec276197"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('python3613': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
